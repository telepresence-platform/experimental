<!DOCTYPE html>
<html>

<head>
    <title>Opencv.js camShift tracking</title>
</head>
<style>
    body {
        -webkit-user-select: none;
        /*Prevent to choose text when long click on mobile*/
        overscroll-behavior: none;
        /*Prevent to pull-to-refresh on mobile*/
    }
</style>
<script async src="https://docs.opencv.org/3.4/opencv.js"></script>

<body>
    <button id="toggleStream" onclick="toggleStream()">Play</button>
    <button id= "camera_change" onclick="camera_change()">back camera</button>

    <video id="video" style="display: none;"></video>
    <canvas id='output'></canvas>
</body>
<script>
    let width, height;
   /* function setSize() {
        if (window.orientation == 0) {
            width = 720; height = 1280; //portrait
        }
        else {
            width = 1280; height = 720; //landscape
        }
    }
    
    setSize();
    
   */
    //カメラデフォルト設定
    constraints = {
        video: { facingMode: "user", }, audio: false
    };
    const video = document.getElementById("video");
    const canvas = document.getElementById('output');
    const canvasPos = canvas.getBoundingClientRect();
    //canvas.width = width; canvas.height = height;
    canvas.addEventListener('mousedown', down); //マウスポインタがおされた
    canvas.addEventListener('mouseup', up); //マウスポインタがあがった
    canvas.addEventListener('touchstart', down); //タッチポインタがおされた 
    canvas.addEventListener('touchend', up); //タッチポインタがあがった




    function camera_change(){ //playをクリックしてからカメラを切り替える
            //video trackを停止
            //カメラをenvironmentに切り替え
            constraints = {
                 video: { facingMode: "environment"}, audio: false
             };
             camera(constraints);
             streaming = !streaming;


    }

    

    let streaming = false;


    function camera(constraints){
        if (streaming === false) {
            navigator.mediaDevices.getUserMedia(constraints)
            .then(function(stream){
                document.querySelector('video').srcObject = stream;
                width=stream.getVideoTracks()[0].getSettings().width;
                height=stream.getVideoTracks()[0].getSettings().height;
                console.log(width,height);
                
                video.onloadedmetadata = function(e){
                    video.width = width; video.height = height;
                    canvas.width = width; canvas.height = height;
                    video.play();
                    setTimeout(setupCV, 0);
                }
                document.getElementById('toggleStream').innerHTML = "Stop";
                
                
            })
            .catch(function(err){
                console.log(error);
            });
        }
         
        else{
            const stream = video.srcObject;
            const tracks = stream.getTracks();
            tracks[0].stop();
            document.getElementById('toggleStream').innerHTML = "Play";
        }
    }
    function toggleStream() {
       
        camera(constraints);
        streaming = !streaming;
    }

    let drawing = false;
    let startX, startY, endX, endY;
    function down(evt) {
        try {
           
            startX = Math.round(evt.touches[0].clientX - canvasPos.left);
            startY = Math.round(evt.touches[0].clientY - canvasPos.top);

            calcPos();
 
        } catch{
           
            startX = Math.round(evt.clientX - canvasPos.left);
            startY = Math.round(evt.clientY - canvasPos.top);

            
            
            console.log("%d,%d,%d,%d",evt.clientX, evt.clientY,canvasPos.left, canvasPos.top);

            calcPos();
            
        }
        
        drawing = true;
        tracking = false;
        inProcess = false;
    }

    let tracking = false;
    function up(evt) {
        drawing = false;　//トラッキング領域指定完了
        tracking = true; //トラッキング開始
        setTimeout(stoptracking,4000);
      

    }

    function calcPos(){
        //startx, startY, endX, endYを一定の矩形に
        startX = startX -25 ;
        startY = startY -25 ;
        endX = startX + 50;
        endY = startY + 50;

        //console.log("startX:%d, startY:%d, endX:%d, endY:%d",startX, startY, endX, endY);
            
    }
    function stoptracking(){
        drawing = false;
        tracking = false;
    }

    let frame, cap;

    async function setupCV() {
        if (frame == undefined) {
            cap = await new cv.VideoCapture('video');
            frame = await new cv.Mat(height, width, cv.CV_8UC4);
            console.log("cv setup complete.");
        }
        setTimeout(process, 0);
    }

    function process() {
        if (streaming === true) {
            cap.read(frame);
            if (drawing === true) {
                cv.rectangle(frame, new cv.Point(startX, startY), new cv.Point(endX, endY), new cv.Scalar(255, 0, 0, 255), 2);
            }
            if (tracking === true) {
                try {
                    
                    camShift();
                }
                catch {
                    console.log("Error on meanshift.");
                    tracking = false;
                }
            }
            cv.imshow('output', frame);
            setTimeout(process, 33); //processをループ
        }
    }

 
    let inProcess = false;
    let trackWindow, roi, hsvRoi, mask, lowScalar, highScalar, low, high, roiHist, hsvRoiVec, termCrit, hsv, dst, hsvVec, trackBox;
    function camShift() {
        if (inProcess === false) {
            console.log('Setup meanshift.');
            inProcess = true;

            const p1 = startX;
            const p2 = startY;
            const p3 = endX - startX;
            const p4 = endY - startY;
          
            trackWindow = new cv.Rect(p1, p2, p3, p4);
            roi = frame.roi(trackWindow);
            hsvRoi = new cv.Mat();
            cv.cvtColor(roi, hsvRoi, cv.COLOR_RGBA2RGB);
            cv.cvtColor(hsvRoi, hsvRoi, cv.COLOR_RGB2HSV);
            mask = new cv.Mat();
            lowScalar = new cv.Scalar(30, 30, 0);
            highScalar = new cv.Scalar(180, 180, 180);
            low = new cv.Mat(hsvRoi.rows, hsvRoi.cols, hsvRoi.type(), lowScalar);//
            high = new cv.Mat(hsvRoi.rows, hsvRoi.cols, hsvRoi.type(), highScalar);//
            cv.inRange(hsvRoi, low, high, mask);
            roiHist = new cv.Mat();
            hsvRoiVec = new cv.MatVector();
            hsvRoiVec.push_back(hsvRoi);
            cv.calcHist(hsvRoiVec, [0], mask, roiHist, [180], [0, 180]);
            cv.normalize(roiHist, roiHist, 0, 255, cv.NORM_MINMAX);

            roi.delete(); hsvRoi.delete(); mask.delete(); low.delete(); high.delete(); hsvRoiVec.delete();
            termCrit = new cv.TermCriteria(cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1);

            hsv = new cv.Mat(height, width, cv.CV_8UC3);
            dst = new cv.Mat();
            hsvVec = new cv.MatVector();
            hsvVec.push_back(hsv);
            trackBox = null;
        }

        cap.read(frame);
        cv.cvtColor(frame, hsv, cv.COLOR_RGBA2RGB);
        cv.cvtColor(hsv, hsv, cv.COLOR_RGB2HSV);
        cv.calcBackProject(hsvVec, [0], roiHist, dst, [0, 180], 1);
        
        [trackBox, trackWindow] = cv.CamShift(dst, trackWindow, termCrit);

        // Draw it on image
        let pts = cv.rotatedRectPoints(trackBox);
       
        if(pts[0].x == pts[1].x == pts[2].x == pts[3].x){
            console.log(pts);
        }

        else{
            cv.line(frame, pts[0], pts[1], [255, 0, 0, 255], 3);
            cv.line(frame, pts[1], pts[2], [255, 0, 0, 255], 3);
            cv.line(frame, pts[2], pts[3], [255, 0, 0, 255], 3);
            cv.line(frame, pts[3], pts[0], [255, 0, 0, 255], 3);

       
            let centerx =　(pts[0].x+pts[1].x+pts[2].x+pts[3].x)/4;
            let centery = (pts[0].y+pts[1].y+pts[2].y+pts[3].y)/4;
            cv.circle(frame, new cv.Point(centerx, centery),20,[255,0,0,255],3);
        }
        
       

    }
    
</script>

</html>
